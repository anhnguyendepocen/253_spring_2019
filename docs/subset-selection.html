<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Topic 5 Subset Selection | MATH 253: Machine Learning</title>
  <meta name="description" content="This is the class activity manual for Math 253 at Macalester College.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Topic 5 Subset Selection | MATH 253: Machine Learning" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is the class activity manual for Math 253 at Macalester College." />
  <meta name="github-repo" content="lmyint/253_spring_2019" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Topic 5 Subset Selection | MATH 253: Machine Learning" />
  
  <meta name="twitter:description" content="This is the class activity manual for Math 253 at Macalester College." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="cross-validation.html">
<link rel="next" href="shrinkageregularization.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; background-color: #2a211c; color: #bdae9d; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; background-color: #2a211c; color: #bdae9d; border-right: 1px solid #bdae9d; }
td.sourceCode { padding-left: 5px; }
pre, code { color: #bdae9d; background-color: #2a211c; }
code > span.kw { color: #43a8ed; font-weight: bold; } /* Keyword */
code > span.dt { text-decoration: underline; } /* DataType */
code > span.dv { color: #44aa43; } /* DecVal */
code > span.bn { color: #44aa43; } /* BaseN */
code > span.fl { color: #44aa43; } /* Float */
code > span.ch { color: #049b0a; } /* Char */
code > span.st { color: #049b0a; } /* String */
code > span.co { color: #0066ff; font-style: italic; } /* Comment */
code > span.al { color: #ffff00; } /* Alert */
code > span.fu { color: #ff9358; font-weight: bold; } /* Function */
code > span.er { color: #ffff00; font-weight: bold; } /* Error */
code > span.wa { color: #ffff00; font-weight: bold; } /* Warning */
code > span.cn { } /* Constant */
code > span.sc { color: #049b0a; } /* SpecialChar */
code > span.vs { color: #049b0a; } /* VerbatimString */
code > span.ss { color: #049b0a; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { color: #43a8ed; font-weight: bold; } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { font-weight: bold; } /* Preprocessor */
code > span.at { } /* Attribute */
code > span.do { color: #0066ff; font-style: italic; } /* Documentation */
code > span.an { color: #0066ff; font-weight: bold; font-style: italic; } /* Annotation */
code > span.co { color: #0066ff; font-weight: bold; font-style: italic; } /* Comment */
code > span.in { color: #0066ff; font-weight: bold; font-style: italic; } /* Information */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href = "./">MATH 253: Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html"><i class="fa fa-check"></i>Schedule</a><ul>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#tentative-overall-schedule"><i class="fa fa-check"></i>Tentative overall schedule</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-2-128---21"><i class="fa fa-check"></i>Week 2: 1/28 - 2/1</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-3-24---28"><i class="fa fa-check"></i>Week 3: 2/4 - 2/8</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-4-211---215"><i class="fa fa-check"></i>Week 4: 2/11 - 2/15</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-5-218---222"><i class="fa fa-check"></i>Week 5: 2/18 - 2/22</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-6-225---31"><i class="fa fa-check"></i>Week 6: 2/25 - 3/1</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-7-34---38"><i class="fa fa-check"></i>Week 7: 3/4 - 3/8</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-8-311---315"><i class="fa fa-check"></i>Week 8: 3/11 - 3/15</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-9-325---329"><i class="fa fa-check"></i>Week 9: 3/25 - 3/29</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-10-41---45"><i class="fa fa-check"></i>Week 10: 4/1 - 4/5</a></li>
<li class="chapter" data-level="" data-path="schedule.html"><a href="schedule.html#week-11-48---412"><i class="fa fa-check"></i>Week 11: 4/8 - 4/12</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="ml-and-society.html"><a href="ml-and-society.html"><i class="fa fa-check"></i>ML and Society</a></li>
<li class="part"><span><b>I Regression: Model Evaluation</b></span></li>
<li class="chapter" data-level="1" data-path="motivation-and-review.html"><a href="motivation-and-review.html"><i class="fa fa-check"></i><b>1</b> Motivation and Review</a><ul>
<li class="chapter" data-level="1.1" data-path="motivation-and-review.html"><a href="motivation-and-review.html#activity-motivating-main-ideas"><i class="fa fa-check"></i><b>1.1</b> Activity: motivating main ideas</a><ul>
<li class="chapter" data-level="" data-path="motivation-and-review.html"><a href="motivation-and-review.html#situation-a"><i class="fa fa-check"></i>Situation A</a></li>
<li class="chapter" data-level="" data-path="motivation-and-review.html"><a href="motivation-and-review.html#situation-b"><i class="fa fa-check"></i>Situation B</a></li>
<li class="chapter" data-level="" data-path="motivation-and-review.html"><a href="motivation-and-review.html#situation-c"><i class="fa fa-check"></i>Situation C</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="motivation-and-review.html"><a href="motivation-and-review.html#review-exercises"><i class="fa fa-check"></i><b>1.2</b> Review exercises</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="regression-assumptions.html"><a href="regression-assumptions.html"><i class="fa fa-check"></i><b>2</b> Regression Assumptions</a><ul>
<li class="chapter" data-level="2.1" data-path="regression-assumptions.html"><a href="regression-assumptions.html#discussion"><i class="fa fa-check"></i><b>2.1</b> Discussion</a></li>
<li class="chapter" data-level="2.2" data-path="regression-assumptions.html"><a href="regression-assumptions.html#exercises"><i class="fa fa-check"></i><b>2.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="accuracy-metrics-for-regression.html"><a href="accuracy-metrics-for-regression.html"><i class="fa fa-check"></i><b>3</b> Accuracy Metrics for Regression</a><ul>
<li class="chapter" data-level="3.1" data-path="accuracy-metrics-for-regression.html"><a href="accuracy-metrics-for-regression.html#discussion-1"><i class="fa fa-check"></i><b>3.1</b> Discussion</a></li>
<li class="chapter" data-level="3.2" data-path="accuracy-metrics-for-regression.html"><a href="accuracy-metrics-for-regression.html#exercises-1"><i class="fa fa-check"></i><b>3.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cross-validation.html"><a href="cross-validation.html"><i class="fa fa-check"></i><b>4</b> Cross-Validation</a><ul>
<li class="chapter" data-level="4.1" data-path="cross-validation.html"><a href="cross-validation.html#discussion-2"><i class="fa fa-check"></i><b>4.1</b> Discussion</a></li>
<li class="chapter" data-level="4.2" data-path="cross-validation.html"><a href="cross-validation.html#exercises-2"><i class="fa fa-check"></i><b>4.2</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>II Regression: Model Building</b></span></li>
<li class="chapter" data-level="5" data-path="subset-selection.html"><a href="subset-selection.html"><i class="fa fa-check"></i><b>5</b> Subset Selection</a><ul>
<li class="chapter" data-level="5.1" data-path="subset-selection.html"><a href="subset-selection.html#discussion-3"><i class="fa fa-check"></i><b>5.1</b> Discussion</a></li>
<li class="chapter" data-level="5.2" data-path="subset-selection.html"><a href="subset-selection.html#exercises-3"><i class="fa fa-check"></i><b>5.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="shrinkageregularization.html"><a href="shrinkageregularization.html"><i class="fa fa-check"></i><b>6</b> Shrinkage/Regularization</a><ul>
<li class="chapter" data-level="6.1" data-path="shrinkageregularization.html"><a href="shrinkageregularization.html#discussion-4"><i class="fa fa-check"></i><b>6.1</b> Discussion</a></li>
<li class="chapter" data-level="6.2" data-path="shrinkageregularization.html"><a href="shrinkageregularization.html#exercises-4"><i class="fa fa-check"></i><b>6.2</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>III Regression: More Flexibility</b></span></li>
<li class="chapter" data-level="7" data-path="knn-bias-variance-tradeoff.html"><a href="knn-bias-variance-tradeoff.html"><i class="fa fa-check"></i><b>7</b> KNN &amp; Bias-Variance Tradeoff</a><ul>
<li class="chapter" data-level="7.1" data-path="knn-bias-variance-tradeoff.html"><a href="knn-bias-variance-tradeoff.html#discussion-5"><i class="fa fa-check"></i><b>7.1</b> Discussion</a></li>
<li class="chapter" data-level="7.2" data-path="knn-bias-variance-tradeoff.html"><a href="knn-bias-variance-tradeoff.html#exercises-5"><i class="fa fa-check"></i><b>7.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="splines.html"><a href="splines.html"><i class="fa fa-check"></i><b>8</b> Splines</a><ul>
<li class="chapter" data-level="8.1" data-path="splines.html"><a href="splines.html#discussion-6"><i class="fa fa-check"></i><b>8.1</b> Discussion</a></li>
<li class="chapter" data-level="8.2" data-path="splines.html"><a href="splines.html#exercises-6"><i class="fa fa-check"></i><b>8.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="local-regression-and-gams.html"><a href="local-regression-and-gams.html"><i class="fa fa-check"></i><b>9</b> Local Regression and GAMs</a><ul>
<li class="chapter" data-level="9.1" data-path="local-regression-and-gams.html"><a href="local-regression-and-gams.html#discussion-7"><i class="fa fa-check"></i><b>9.1</b> Discussion</a></li>
<li class="chapter" data-level="9.2" data-path="local-regression-and-gams.html"><a href="local-regression-and-gams.html#exercises-7"><i class="fa fa-check"></i><b>9.2</b> Exercises</a></li>
<li class="chapter" data-level="9.3" data-path="local-regression-and-gams.html"><a href="local-regression-and-gams.html#how-to-choose-between-methods"><i class="fa fa-check"></i><b>9.3</b> How to choose between methods?!?</a></li>
</ul></li>
<li class="part"><span><b>IV Classification</b></span></li>
<li class="chapter" data-level="10" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>10</b> Logistic Regression</a><ul>
<li class="chapter" data-level="10.1" data-path="logistic-regression.html"><a href="logistic-regression.html#discussion-8"><i class="fa fa-check"></i><b>10.1</b> Discussion</a></li>
<li class="chapter" data-level="10.2" data-path="logistic-regression.html"><a href="logistic-regression.html#exercises-8"><i class="fa fa-check"></i><b>10.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="revisiting-old-tools.html"><a href="revisiting-old-tools.html"><i class="fa fa-check"></i><b>11</b> Revisiting Old Tools</a><ul>
<li class="chapter" data-level="11.1" data-path="revisiting-old-tools.html"><a href="revisiting-old-tools.html#discussion-9"><i class="fa fa-check"></i><b>11.1</b> Discussion</a></li>
<li class="chapter" data-level="11.2" data-path="revisiting-old-tools.html"><a href="revisiting-old-tools.html#exercises-9"><i class="fa fa-check"></i><b>11.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>12</b> Decision Trees</a><ul>
<li class="chapter" data-level="12.1" data-path="decision-trees.html"><a href="decision-trees.html#discussion-10"><i class="fa fa-check"></i><b>12.1</b> Discussion</a></li>
<li class="chapter" data-level="12.2" data-path="decision-trees.html"><a href="decision-trees.html#exercises-10"><i class="fa fa-check"></i><b>12.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html"><i class="fa fa-check"></i><b>13</b> Bagging and Random Forests</a><ul>
<li class="chapter" data-level="13.1" data-path="bagging-and-random-forests.html"><a href="bagging-and-random-forests.html#exercises-11"><i class="fa fa-check"></i><b>13.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="support-vector-machines-part-1.html"><a href="support-vector-machines-part-1.html"><i class="fa fa-check"></i><b>14</b> Support Vector Machines (Part 1)</a><ul>
<li class="chapter" data-level="14.1" data-path="support-vector-machines-part-1.html"><a href="support-vector-machines-part-1.html#exercises-12"><i class="fa fa-check"></i><b>14.1</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="support-vector-machines-part-2.html"><a href="support-vector-machines-part-2.html"><i class="fa fa-check"></i><b>15</b> Support Vector Machines (Part 2)</a><ul>
<li class="chapter" data-level="15.1" data-path="support-vector-machines-part-2.html"><a href="support-vector-machines-part-2.html#exercises-13"><i class="fa fa-check"></i><b>15.1</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>V Unsupervised Learning</b></span></li>
<li class="chapter" data-level="16" data-path="k-means-clustering.html"><a href="k-means-clustering.html"><i class="fa fa-check"></i><b>16</b> K-Means Clustering</a><ul>
<li class="chapter" data-level="16.1" data-path="k-means-clustering.html"><a href="k-means-clustering.html#discussion-11"><i class="fa fa-check"></i><b>16.1</b> Discussion</a></li>
<li class="chapter" data-level="16.2" data-path="k-means-clustering.html"><a href="k-means-clustering.html#exercises-14"><i class="fa fa-check"></i><b>16.2</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html"><i class="fa fa-check"></i><b>17</b> Hierarchical Clustering</a><ul>
<li class="chapter" data-level="17.1" data-path="hierarchical-clustering.html"><a href="hierarchical-clustering.html#exercises-15"><i class="fa fa-check"></i><b>17.1</b> Exercises</a></li>
</ul></li>
<li class="part"><span><b>Review</b></span></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html"><i class="fa fa-check"></i>Midterm Review</a><ul>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#organizing-information-on-all-methods"><i class="fa fa-check"></i>Organizing information on all methods</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#review-of-specific-methods"><i class="fa fa-check"></i>Review of specific methods</a><ul>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#subset-selection-1"><i class="fa fa-check"></i>Subset selection</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#lasso"><i class="fa fa-check"></i>LASSO</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#splines-1"><i class="fa fa-check"></i>Splines</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#generalzed-additive-models-gams"><i class="fa fa-check"></i>Generalzed additive models (GAMs)</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#knn-and-decision-trees"><i class="fa fa-check"></i>KNN and decision trees</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#logistic-regression-1"><i class="fa fa-check"></i>Logistic regression</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#bagging-and-random-forests-1"><i class="fa fa-check"></i>Bagging and random forests</a></li>
<li class="chapter" data-level="" data-path="midterm-review.html"><a href="midterm-review.html#test-set-performance"><i class="fa fa-check"></i>Test set performance</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>Final Project</b></span></li>
<li class="chapter" data-level="" data-path="final-project-instructions.html"><a href="final-project-instructions.html"><i class="fa fa-check"></i>Final Project Instructions</a><ul>
<li class="chapter" data-level="" data-path="final-project-instructions.html"><a href="final-project-instructions.html#overview"><i class="fa fa-check"></i>Overview</a></li>
<li class="chapter" data-level="" data-path="final-project-instructions.html"><a href="final-project-instructions.html#initial-check-in"><i class="fa fa-check"></i>Initial check-in</a></li>
<li class="chapter" data-level="" data-path="final-project-instructions.html"><a href="final-project-instructions.html#final-report"><i class="fa fa-check"></i>Final report</a></li>
<li class="chapter" data-level="" data-path="final-project-instructions.html"><a href="final-project-instructions.html#final-presentation"><i class="fa fa-check"></i>Final presentation</a></li>
</ul></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="cross-validation-1.html"><a href="cross-validation-1.html"><i class="fa fa-check"></i><b>A</b> Cross-Validation</a><ul>
<li class="chapter" data-level="A.1" data-path="cross-validation-1.html"><a href="cross-validation-1.html#objects"><i class="fa fa-check"></i><b>A.1</b> Objects</a></li>
<li class="chapter" data-level="A.2" data-path="cross-validation-1.html"><a href="cross-validation-1.html#subsetting"><i class="fa fa-check"></i><b>A.2</b> Subsetting</a></li>
<li class="chapter" data-level="A.3" data-path="cross-validation-1.html"><a href="cross-validation-1.html#writing-r-functions"><i class="fa fa-check"></i><b>A.3</b> Writing R functions</a></li>
<li class="chapter" data-level="A.4" data-path="cross-validation-1.html"><a href="cross-validation-1.html#for-loops-and-control-flow"><i class="fa fa-check"></i><b>A.4</b> <code>for</code>-loops and control flow</a></li>
<li class="chapter" data-level="A.5" data-path="cross-validation-1.html"><a href="cross-validation-1.html#building-our-cross-validation-function"><i class="fa fa-check"></i><b>A.5</b> Building our cross-validation function!</a></li>
<li class="chapter" data-level="A.6" data-path="cross-validation-1.html"><a href="cross-validation-1.html#aside-apply-functions"><i class="fa fa-check"></i><b>A.6</b> Aside: <code>apply()</code> functions</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="splines-2.html"><a href="splines-2.html"><i class="fa fa-check"></i><b>B</b> Splines</a><ul>
<li class="chapter" data-level="B.1" data-path="splines-2.html"><a href="splines-2.html#exercise"><i class="fa fa-check"></i><b>B.1</b> Exercise</a></li>
<li class="chapter" data-level="B.2" data-path="splines-2.html"><a href="splines-2.html#debriefing"><i class="fa fa-check"></i><b>B.2</b> Debriefing</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">MATH 253: Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="subset-selection" class="section level1">
<h1><span class="header-section-number">Topic 5</span> Subset Selection</h1>
<div id="discussion-3" class="section level2">
<h2><span class="header-section-number">5.1</span> Discussion</h2>
<div class="figure">
<img src="images/class_flow2.png" />

</div>
<p><br> <br> <br> <br></p>
<p><strong>Subset selection methods</strong></p>
<ul>
<li>Automated methods that take different strategies for exploring subsets of the predictors</li>
<li>Stepwise selection methods: add or remove variables one at a time</li>
<li>Best subset selection: brute force method that tries all possible subsets of predictors</li>
</ul>
<p><br> <br> <br> <br> <br> <br></p>
</div>
<div id="exercises-3" class="section level2">
<h2><span class="header-section-number">5.2</span> Exercises</h2>
<p><strong>You can download a template RMarkdown file to start from <a href="template_rmds/05-subset-selection.Rmd">here</a>.</strong></p>
<p>We’ll continue using the body fat dataset to explore subset selection methods.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(dplyr)
bodyfat &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;http://www.macalester.edu/~ajohns24/data/bodyfatsub.csv&quot;</span>)

<span class="co"># Take out the redundant Density and HeightFt variables</span>
bodyfat &lt;-<span class="st"> </span>bodyfat <span class="op">%&gt;%</span><span class="st"> </span>
<span class="st">    </span><span class="kw">select</span>(<span class="op">-</span>Density, <span class="op">-</span>HeightFt)</code></pre></div>
<ol style="list-style-type: decimal">
<li><p><strong>Backward stepwise selection: by hand</strong><br />
In the backward stepwise procedure, we start with the full model, <code>full_model</code>, with <em>all</em> predictors:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">full_model &lt;-<span class="st"> </span><span class="kw">lm</span>(BodyFat <span class="op">~</span><span class="st"> </span>Age <span class="op">+</span><span class="st"> </span>Weight <span class="op">+</span><span class="st"> </span>Height <span class="op">+</span><span class="st"> </span>Neck <span class="op">+</span><span class="st"> </span>Chest <span class="op">+</span><span class="st"> </span>Abdomen <span class="op">+</span><span class="st"> </span>Hip <span class="op">+</span><span class="st"> </span>Thigh <span class="op">+</span><span class="st"> </span>Knee <span class="op">+</span><span class="st"> </span>Ankle <span class="op">+</span><span class="st"> </span>Biceps <span class="op">+</span><span class="st"> </span>Forearm <span class="op">+</span><span class="st"> </span>Wrist, <span class="dt">data =</span> bodyfat)</code></pre></div>
<p>Then…</p>
<ul>
<li><p>Identify which predictor contributes the <em>least</em> to the model. One approach is to identify the least significant predictor.</p></li>
<li><p>Fit a new model which eliminates this predictor.</p></li>
<li><p>Identify the least significant predictor in this model.</p></li>
<li><p>Fit a new model which eliminates this predictor.</p></li>
<li><p>Repeat 1 more time to get the hang of it.</p></li>
</ul></li>
</ol>
<p><br> <br> <br> <br></p>
<ol start="2" style="list-style-type: decimal">
<li><strong>Interpreting the results</strong>
<ol style="list-style-type: lower-alpha">
<li>Examine which predictors remain after the previous exercise. Are you surprised that, for example, <code>Wrist</code> is still in the model but <code>Weight</code> is not? Does this mean that <code>Wrist</code> is a better predictor of body fat percentage than <code>Weight</code> is?</li>
<li><em>Forward selection</em> is another stepwise technique. Can you guess how this differs from backward selection?</li>
<li><em>Best subset selection</em> is another subset selection technique that looks at every possible subset of predictors, fits all of these models, and picks the best one. From the perspective of computational time, why is this not a preferable approach?</li>
</ol></li>
</ol>
<p><br> <br> <br> <br></p>
<ol start="3" style="list-style-type: decimal">
<li><strong>Planning backward selection using CV</strong><br />
Using p-values to perform backward selection by hand is convenient but not the most direct way to target predictive accuracy. Outline the steps that you would take to use cross-validation to perform backward selection. (Write an algorithm in words.)</li>
</ol>
<p><br> <br> <br> <br></p>
<ol start="4" style="list-style-type: decimal">
<li><p><strong>Backward stepwise selection in <code>caret</code></strong><br />
We can use the <code>caret</code> package to perform backward stepwise selection with cross-validation as shown below. (<strong>Note:</strong> CV is only used to pick among the best 1, 2, 3, …, and 13 variable models. To find the best 1, 2, 3, …, and 13 variable models, training MSE is used. <code>caret</code> uses training MSE because within a subset size, all models have the same number of coefficients, which makes both ordinary R-squared and training MSE ok.) Just focus on the structure of the code and how different parts of the output are used.<br />
Is there a use case that you are interested in but don’t see below? Feel free to ask the instructor about it!</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(caret)

<span class="co"># Set up cross-validation information</span>
train_ctrl_cv10 &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="dt">number =</span> <span class="dv">10</span>)

<span class="co"># Perform backward stepwise selection</span>
<span class="co"># The first time you run this, you&#39;ll be prompted to install the &quot;leaps&quot; package</span>
<span class="kw">set.seed</span>(<span class="dv">253</span>)
back_step &lt;-<span class="st"> </span><span class="kw">train</span>(
    BodyFat <span class="op">~</span><span class="st"> </span>.,
    <span class="dt">data =</span> bodyfat,
    <span class="dt">method =</span> <span class="st">&quot;leapBackward&quot;</span>,
    <span class="dt">tuneGrid =</span> <span class="kw">data.frame</span>(<span class="dt">nvmax =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">13</span>),
    <span class="dt">trControl =</span> train_ctrl_cv10,
    <span class="dt">metric =</span> <span class="st">&quot;RMSE&quot;</span>,
    <span class="dt">na.action =</span> na.omit
)

<span class="co"># Look at accuracy/error metrics for the different subset sizes</span>
back_step<span class="op">$</span>results

<span class="co"># What tuning parameter gave the best performance?</span>
<span class="co"># i.e. What subset size gave the best model?</span>
back_step<span class="op">$</span>bestTune

<span class="co"># Obtain the coefficients for the best model</span>
<span class="kw">coefficients</span>(back_step<span class="op">$</span>finalModel, <span class="dt">id =</span> back_step<span class="op">$</span>bestTune<span class="op">$</span>nvmax)

<span class="co"># Use the best model to make predictions on new data</span>
<span class="kw">predict</span>(back_step, <span class="dt">newdata =</span> bodyfat)</code></pre></div>
<p>Some notes about the code:</p>
<ul>
<li>The <code>BodyFat ~ .</code> formula tells R that <code>BodyFat</code> is the response and that all predictors (specified with the <code>.</code>) will be considered.</li>
<li>The <code>tuneGrid</code> argument allows us to input tuning parameters into the fitting process. The tuning parameters here are the number of variables included in the models (<code>nvmax</code>). This can vary from 1 to 13 (the maximum number of predictors possible).</li>
<li>The <code>metric</code> argument indicates how the best of the 1-variable, 2-variable, etc. models will be chosen. We’ll use RMSE (root mean squared error).</li>
<li>When you look at <code>back_step$results</code>, you’ll see a matrix of output. The rows correspond to the different subset sizes. For each subset size you’ll see the RMSE, <span class="math inline">\(R^2\)</span>, and MAE accuracy/error metrics. Recall that these are estimates that arise by taking the mean of the values given in the 10 CV iterations. The 10 values from the 10 iterations also have a standard deviation. These are reported in the last 3 columns. What use might the standard deviation have in picking a final model?</li>
</ul></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cross-validation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="shrinkageregularization.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
